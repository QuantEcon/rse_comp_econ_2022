{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "40d2195a",
      "metadata": {
        "id": "40d2195a"
      },
      "source": [
        "# Parallelization Example: Dynamic Programming on the GPU\n",
        "\n",
        "Author: [John Stachurski](https://johnstachurski.net/)\n",
        "\n",
        "Parallelization on GPUs is one of the major trends of modern scientific computing.\n",
        "\n",
        "In this notebook we examine a part of a dynamic programming exercise on\n",
        "the GPU using Python and the [Google JAX\n",
        "library](https://jax.readthedocs.io/en/latest/index.html).\n",
        "\n",
        "\n",
        "\n",
        "## Computing task:\n",
        "\n",
        "Implement the Bellman operator, which takes an array $v$ and computes a new array $Tv$, defined by\n",
        "\n",
        "$$\n",
        "    (Tv)(a, y) = \n",
        "    \\max_{0 \\leq a' \\leq Ra + y}\n",
        "    \\left\\{\n",
        "    u(Ra + y - a') + \\beta \\sum_{y'} v(a', y') P(y, y')\n",
        "    \\right\\}.\n",
        "$$\n",
        "\n",
        "This is part of a dynamic programming exercise that computes optimal savings and comsumption given assets, the interest rate and labor income.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c4fdca8",
      "metadata": {
        "id": "1c4fdca8"
      },
      "source": [
        "The next cell supresses some unnecessary NumPy warnings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d9ea81d1",
      "metadata": {
        "id": "d9ea81d1"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a07c177e",
      "metadata": {
        "id": "a07c177e"
      },
      "source": [
        "First we import some libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "qpO_8-Ha3F7z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpO_8-Ha3F7z",
        "outputId": "231b83e6-19fb-405e-d351-6520d9bfb922"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting quantecon\n",
            "  Downloading quantecon-0.5.3-py3-none-any.whl (179 kB)\n",
            "\u001b[K     |████████████████████████████████| 179 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from quantecon) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from quantecon) (1.21.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from quantecon) (1.7.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from quantecon) (0.51.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from quantecon) (2.23.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->quantecon) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->quantecon) (57.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->quantecon) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->quantecon) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->quantecon) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->quantecon) (1.24.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->quantecon) (1.2.1)\n",
            "Installing collected packages: quantecon\n",
            "Successfully installed quantecon-0.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install -U quantecon "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "da4873ac",
      "metadata": {
        "id": "da4873ac"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from numba import njit\n",
        "import quantecon as qe \n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9975d552",
      "metadata": {
        "id": "9975d552"
      },
      "source": [
        "Next we specify some primitives, including the utility function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "29643599",
      "metadata": {
        "id": "29643599"
      },
      "outputs": [],
      "source": [
        "R = 1.1\n",
        "β = 0.99\n",
        "γ = 2.5\n",
        "\n",
        "def u(c):\n",
        "    return c**(1-γ) / (1-γ)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "884bac7b",
      "metadata": {
        "id": "884bac7b"
      },
      "source": [
        "Now we define the asset grid (the set of values for $a$ and $a'$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4e10b3ab",
      "metadata": {
        "id": "4e10b3ab"
      },
      "outputs": [],
      "source": [
        "a_min, a_max = 0.01, 2\n",
        "a_size = ap_size = 1000\n",
        "a_grid = np.linspace(a_min, a_max, a_size)  # grid for a\n",
        "ap_grid = np.copy(a_grid)                   # grid for a'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "021394a8",
      "metadata": {
        "id": "021394a8"
      },
      "source": [
        "Next we build the Markov matrix $P$ for income.  We will use QuantEcon's `tauchen()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f22b1210",
      "metadata": {
        "id": "f22b1210"
      },
      "outputs": [],
      "source": [
        "ρ = 0.9\n",
        "σ = 0.1\n",
        "y_size = 100\n",
        "mc = qe.tauchen(ρ, σ, n=y_size)\n",
        "y_grid = np.exp(mc.state_values)\n",
        "P = mc.P"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33f21f47",
      "metadata": {
        "id": "33f21f47"
      },
      "source": [
        "## A First Pass: Using Loops and Numba\n",
        "\n",
        "As our first implementation of the Bellman operator, we are going to use loops over the state and choice variables.  The use of `njit` in the code below indicates that we are using Numba to just-in-time (JIT) compile the utility function and the Bellman operator.  This makes the loops inside the Bellman operator run at the same speed as compiled C or Fortran code.\n",
        "\n",
        "We are applying Numba's JIT functionality so that we have a serious --- but not parallelized --- benchmark, running on the CPU.\n",
        "\n",
        "Below we will compare this benchmark to implementations on the GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2351774b",
      "metadata": {
        "id": "2351774b"
      },
      "outputs": [],
      "source": [
        "u_jit = njit(u)  # Compile the utility function\n",
        "\n",
        "@njit\n",
        "def T(v):\n",
        "    \"The Bellman operator.\"\n",
        "    # Allocate memory\n",
        "    v_new = np.empty_like(v)\n",
        "    # Step through all states\n",
        "    for i, a in enumerate(a_grid):\n",
        "        for j, y in enumerate(y_grid):\n",
        "            # Choose a' optimally by stepping through all possible values\n",
        "            v_max = - np.inf\n",
        "            for k, ap in enumerate(ap_grid):\n",
        "                c = R * a + y - ap\n",
        "                if c > 0:  \n",
        "                    # Calculate the right hand side of the Belllman operator\n",
        "                    val = u_jit(c) + β * np.dot(v[k, :], P[j, :])\n",
        "                    if val > v_max:\n",
        "                        v_max = val\n",
        "            v_new[i, j] = v_max\n",
        "    return v_new"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c958745",
      "metadata": {
        "id": "1c958745"
      },
      "source": [
        "Here's a vector to test our operator on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "dda13b27",
      "metadata": {
        "id": "dda13b27"
      },
      "outputs": [],
      "source": [
        "vz = np.zeros((a_size, y_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8afe89b4",
      "metadata": {
        "id": "8afe89b4"
      },
      "source": [
        "Now let's apply the operator and see how long it takes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8dfa62a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dfa62a8",
        "outputId": "55b0f7c1-c564-43fc-9053-fd4794c82fff",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 11.8 s, sys: 55.2 ms, total: 11.9 s\n",
            "Wall time: 11.8 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.86623555, -1.82779165, -1.79013867, ..., -0.24736292,\n",
              "        -0.24225994, -0.2372622 ],\n",
              "       [-1.85411787, -1.81608627, -1.77883158, ..., -0.2469437 ,\n",
              "        -0.24185503, -0.23687111],\n",
              "       [-1.84213077, -1.8045053 , -1.76764303, ..., -0.24652566,\n",
              "        -0.24145124, -0.23648109],\n",
              "       ...,\n",
              "       [-0.15126798, -0.15067609, -0.15007985, ..., -0.07968264,\n",
              "        -0.07890307, -0.07812548],\n",
              "       [-0.15108321, -0.15049252, -0.14989749, ..., -0.07961914,\n",
              "        -0.0788406 , -0.07806403],\n",
              "       [-0.15089881, -0.15030933, -0.1497155 , ..., -0.07955571,\n",
              "        -0.07877821, -0.07800266]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "%time T(vz)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "844da4c6",
      "metadata": {
        "id": "844da4c6"
      },
      "source": [
        "## A Second Pass: Vectorization via NumPy\n",
        "\n",
        "Next we try with vectorized operations, meaning that loops need to be replaced by operations on arrays.  We use some NumPy [broadcasting](https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html) tricks to eliminate these loops.\n",
        "\n",
        "The basic idea is to add dimensions to arrays so that they will be stretched along the new dimensions when placed in arithmetic operations with other arrays that have more elements along those dimensions.  This stretching is done by repeating values, which is what we use to replace loops.\n",
        "\n",
        "The next code cell reshapes all arrays to be three-dimensional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "43fbb3d6",
      "metadata": {
        "id": "43fbb3d6"
      },
      "outputs": [],
      "source": [
        "P = np.reshape(P, (y_size, y_size, 1))\n",
        "a = np.reshape(a_grid, (a_size, 1, 1))\n",
        "y = np.reshape(y_grid, (1, y_size, 1))\n",
        "ap = np.reshape(ap_grid, (1, 1, ap_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a709eb2",
      "metadata": {
        "id": "9a709eb2"
      },
      "source": [
        "Now we can implement a vectorized version of the Bellman operator, which calculates the same values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "59455d06",
      "metadata": {
        "id": "59455d06"
      },
      "outputs": [],
      "source": [
        "def T_vec(v):\n",
        "    vp = np.dot(v, P)\n",
        "    c = R * a + y - ap\n",
        "    m = np.where(c > 0, u(c) + β * vp, -np.inf)\n",
        "    return np.max(m, axis=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d0fe4bf",
      "metadata": {
        "id": "1d0fe4bf"
      },
      "source": [
        "At this point, everything is in NumPy, and runs **on the CPU** rather than the GPU.\n",
        "\n",
        "Let's check the output and see how fast it runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4f5b0e11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f5b0e11",
        "outputId": "16910269-f78e-4c33-b958-56b32c195de2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6.49 s, sys: 15.6 ms, total: 6.51 s\n",
            "Wall time: 6.48 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.86623555, -1.82779165, -1.79013867, ..., -0.24736292,\n",
              "        -0.24225994, -0.2372622 ],\n",
              "       [-1.85411787, -1.81608627, -1.77883158, ..., -0.2469437 ,\n",
              "        -0.24185503, -0.23687111],\n",
              "       [-1.84213077, -1.8045053 , -1.76764303, ..., -0.24652566,\n",
              "        -0.24145124, -0.23648109],\n",
              "       ...,\n",
              "       [-0.15126798, -0.15067609, -0.15007985, ..., -0.07968264,\n",
              "        -0.07890307, -0.07812548],\n",
              "       [-0.15108321, -0.15049252, -0.14989749, ..., -0.07961914,\n",
              "        -0.0788406 , -0.07806403],\n",
              "       [-0.15089881, -0.15030933, -0.1497155 , ..., -0.07955571,\n",
              "        -0.07877821, -0.07800266]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "%time T_vec(vz)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6e1efe0",
      "metadata": {
        "id": "c6e1efe0"
      },
      "source": [
        "The output is the same as above, but execution speed is slightly faster.  \n",
        "\n",
        "Where does the speed gain come from, given that we had already compiled our loops in the previous version of $T$?\n",
        "\n",
        "The answer is that NumPy array operations use some degree of multithreading on the CPU with basic array operations.  \n",
        "\n",
        "So we are running operations at a similar speed but making better use of multi-core CPU platforms via parallelization."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8TH7cD0l4izg",
      "metadata": {
        "id": "8TH7cD0l4izg"
      },
      "source": [
        "## Switching to the GPU via JaX"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Be5AJYm942XE",
      "metadata": {
        "id": "Be5AJYm942XE"
      },
      "source": [
        "Next we look to switch to a GPU-based implementation.  First, let's check that Google Colab has assigned us a nice GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "lHDzQN__3rMC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHDzQN__3rMC",
        "outputId": "3b86a7df-4b5b-445c-9745-340466294a0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jul 21 05:01:43 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ynVq7qVg5KzU",
      "metadata": {
        "id": "ynVq7qVg5KzU"
      },
      "source": [
        "When we ran this on Colab, we obtained a Tesla P100, which can be seen in the output above (assuming you are reading this without running it, or that you have been assigned the same GPU).\n",
        "\n",
        "Next let's try to set up a Bellman operator that runs on this GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "1c13f56d",
      "metadata": {
        "id": "1c13f56d"
      },
      "outputs": [],
      "source": [
        "# Shift all NumPy arrays onto the GPU\n",
        "P = jax.device_put(P)\n",
        "a = jax.device_put(a)\n",
        "y = jax.device_put(y)\n",
        "ap = jax.device_put(ap)\n",
        "vz = jax.device_put(vz)\n",
        "\n",
        "# Define the Bellman operator as in the NumPy version, but replacing np with jnp\n",
        "def T_jax(v):\n",
        "    vp = jnp.dot(v, P)\n",
        "    c = R * a + y - ap\n",
        "    m = jnp.where(c > 0, u(c) +   β * vp, -np.inf)\n",
        "    return jnp.max(m, axis=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JzNNIIIu5xjV",
      "metadata": {
        "id": "JzNNIIIu5xjV"
      },
      "source": [
        "Let's look at the timing.  (We use `block_until_ready()` only to force evaluation at the time of function call, so we can do proper benchmarking.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "6cdba533",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cdba533",
        "outputId": "8035c387-8a6b-488c-aff6-f3d8a998ff9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5.08 ms, sys: 35 µs, total: 5.11 ms\n",
            "Wall time: 12.6 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[-1.8662355 , -1.8277917 , -1.7901386 , ..., -0.24736291,\n",
              "              -0.24225995, -0.23726219],\n",
              "             [-1.8541178 , -1.8160865 , -1.7788315 , ..., -0.24694368,\n",
              "              -0.24185503, -0.23687112],\n",
              "             [-1.8421307 , -1.8045052 , -1.7676427 , ..., -0.24652565,\n",
              "              -0.24145123, -0.2364811 ],\n",
              "             ...,\n",
              "             [-0.15126799, -0.15067609, -0.15007983, ..., -0.07968266,\n",
              "              -0.07890309, -0.07812549],\n",
              "             [-0.15108322, -0.15049253, -0.14989749, ..., -0.07961915,\n",
              "              -0.07884061, -0.07806404],\n",
              "             [-0.15089881, -0.15030932, -0.14971548, ..., -0.07955572,\n",
              "              -0.07877821, -0.07800266]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "%time T_jax(vz).block_until_ready()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a9c44ab",
      "metadata": {
        "id": "4a9c44ab"
      },
      "source": [
        "We already have some speed gain from shifting to the GPU.  But we can do even better, using JAX's just-in-time compiler.  First we target `T_jax` for compilation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "336a5d23",
      "metadata": {
        "id": "336a5d23"
      },
      "outputs": [],
      "source": [
        "T_jax_jit = jax.jit(T_jax)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdbacc5c",
      "metadata": {
        "id": "bdbacc5c"
      },
      "source": [
        "When we first run the function there is not much speed gain because the function needs to be compiled before it is run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "7b1c7538",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b1c7538",
        "outputId": "12f3ba35-0f04-4136-a08f-e3d5232627a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 168 ms, sys: 12.1 ms, total: 180 ms\n",
            "Wall time: 311 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[-1.8662355 , -1.8277917 , -1.7901386 , ..., -0.24736291,\n",
              "              -0.24225995, -0.23726219],\n",
              "             [-1.8541178 , -1.8160865 , -1.7788315 , ..., -0.24694368,\n",
              "              -0.24185503, -0.23687112],\n",
              "             [-1.8421307 , -1.8045052 , -1.7676427 , ..., -0.24652565,\n",
              "              -0.24145123, -0.2364811 ],\n",
              "             ...,\n",
              "             [-0.15126799, -0.15067609, -0.15007983, ..., -0.07968266,\n",
              "              -0.07890309, -0.07812549],\n",
              "             [-0.15108322, -0.15049253, -0.14989749, ..., -0.07961915,\n",
              "              -0.07884061, -0.07806404],\n",
              "             [-0.15089881, -0.15030932, -0.14971548, ..., -0.07955572,\n",
              "              -0.07877821, -0.07800266]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "%time T_jax_jit(vz).block_until_ready()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aae0ffc2",
      "metadata": {
        "id": "aae0ffc2"
      },
      "source": [
        "But the next time we run it we get a large speed gain:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "361234e8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "361234e8",
        "outputId": "a65a166e-d25b-4d17-d71f-73a0e2d0d17b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.75 ms, sys: 997 µs, total: 2.74 ms\n",
            "Wall time: 4.47 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[-1.8662355 , -1.8277917 , -1.7901386 , ..., -0.24736291,\n",
              "              -0.24225995, -0.23726219],\n",
              "             [-1.8541178 , -1.8160865 , -1.7788315 , ..., -0.24694368,\n",
              "              -0.24185503, -0.23687112],\n",
              "             [-1.8421307 , -1.8045052 , -1.7676427 , ..., -0.24652565,\n",
              "              -0.24145123, -0.2364811 ],\n",
              "             ...,\n",
              "             [-0.15126799, -0.15067609, -0.15007983, ..., -0.07968266,\n",
              "              -0.07890309, -0.07812549],\n",
              "             [-0.15108322, -0.15049253, -0.14989749, ..., -0.07961915,\n",
              "              -0.07884061, -0.07806404],\n",
              "             [-0.15089881, -0.15030932, -0.14971548, ..., -0.07955572,\n",
              "              -0.07877821, -0.07800266]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "%time T_jax_jit(vz).block_until_ready()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2533099",
      "metadata": {
        "id": "c2533099"
      },
      "source": [
        "That's seriously fast.\n",
        "\n",
        "This new speed gain is possible because JAX's JIT compiler \"fuses\" the array operations inside `T_jax`, which essentially means that it views them as a whole and optimizes accordingly.  This allows generation of highly efficient code for the GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ff4a41c",
      "metadata": {
        "id": "2ff4a41c"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "rse_workshop_jax_example.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}